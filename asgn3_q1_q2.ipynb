{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving Systems of Linear Equations with Python's Numpy\n",
    "\n",
    "+ 4x + 3y + 2z = 25\n",
    "+ -2x + 2y + 3z = -10\n",
    "+ 3x -5y + 2z = -4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[ 5.  3. -2.]\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[4, 3, 2], [-2, 2, 3], [3, -5, 2]])\n",
    "B = np.array([25, -10, -4])\n",
    "X = np.linalg.inv(A).dot(B)\n",
    "\n",
    "print(X)\n",
    "\n",
    "from enum import Enum\n",
    "class Action(Enum):\n",
    "    UP = [-1, 0]\n",
    "    DOWN = [1, 0]\n",
    "    LEFT = [0, -1]\n",
    "    RIGHT = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[[  0. -14. -20. -22.]\n [-14. -18. -20. -20.]\n [-20. -20. -18. -14.]\n [-22. -20. -14.   0.]]\n"
    }
   ],
   "source": [
    "#Question 1\n",
    "#Policy Evalution \n",
    "#Bellman equation and liners system solver\n",
    "Reward = np.arange(16, dtype=float)\n",
    "Reward = Reward.reshape(16,1)\n",
    "Reward = np.negative(np.ones_like(Reward))\n",
    "Reward[0] = 0\n",
    "Reward[15] = 0\n",
    "\n",
    "Prob = np.array([0.25, 0.25, 0.25, 0.25,0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25])\n",
    "#Prob = np.array([0, 1/3, 1/3, 1/2,1/3, 1/4, 1/4, 1/3,1/3, 1/4, 1/4, 1/3,1/2, 1/3, 1/3, 0])\n",
    "Prob = Prob.reshape(4,4)\n",
    "\n",
    "Trans = np.arange(16*16, dtype=float)\n",
    "Trans = Trans.reshape(16, 16)\n",
    "Trans = np.zeros_like(Trans)\n",
    "\n",
    "for i in range(16):\n",
    "    \n",
    "    for j in range(16):\n",
    "        if i == 0 or i == 15 :#or j == 0 or j==15:\n",
    "            Trans[i][j] = 0\n",
    "        else:\n",
    "            if j == i-1 and (j%4) != 3:\n",
    "                Trans[i][j] = Prob[int(i/4)][i%4]\n",
    "            if j == i+1 and (j%4) != 0:\n",
    "                Trans[i][j] = Prob[int(i/4)][i%4]\n",
    "            if j == i-4:\n",
    "                Trans[i][j] = Prob[int(i/4)][i%4]\n",
    "            if j == i+4:\n",
    "                Trans[i][j] = Prob[int(i/4)][i%4]\n",
    "    if i-4 < 0:\n",
    "        Trans[i][i] = 0.25\n",
    "    elif i+4 > 15:\n",
    "        Trans[i][i] = 0.25\n",
    "    if i%4 == 0 or i%4 == 3:\n",
    "        Trans[i][i] = 0.25\n",
    "    if i == 3 or i == 12:\n",
    "        Trans[i][i] = 0.5\n",
    "        \n",
    "Trans = np.identity(16) - Trans\n",
    "            \n",
    "A = np.array(Trans)\n",
    "B = np.array(Reward)\n",
    "\n",
    "val = np.linalg.inv(A).dot(B)\n",
    "\n",
    "val = val.reshape(4, 4)\n",
    "val = np.round(val, 2)\n",
    "print(val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[[  0.   -13.96 -19.94 -21.94]\n [-13.96 -17.95 -19.94 -19.94]\n [-19.94 -19.94 -17.95 -13.96]\n [-21.94 -19.94 -13.96   0.  ]]\n"
    }
   ],
   "source": [
    "#Question 1\n",
    "#Iterative Policy Evalution \n",
    "import math \n",
    "def iterative_policy(row, col, reward, discount):\n",
    "\n",
    "    state = np.arange(row*col, dtype = float)\n",
    "    val = np.arange(row*col, dtype = float)\n",
    "    state = state.reshape((row,col))\n",
    "    val = val.reshape((row,col))\n",
    "    state = np.zeros_like(state)\n",
    "    val = np.zeros_like(val)\n",
    "\n",
    "    while True:\n",
    "        for i in range(row):\n",
    "            for j in range(col):\n",
    "                val[i][j]=0\n",
    "                if i == 0 and j == 0: \n",
    "                    continue\n",
    "                if i == 3 and j == 3:\n",
    "                    continue \n",
    "                if j-1 >= 0:\n",
    "                    val[i][j] += (reward + discount*state[i][j-1])\n",
    "                elif j-1 < 0:\n",
    "                    val[i][j] += (reward + discount*state[i][j])\n",
    "                if j+1 <= col-1:\n",
    "                    val[i][j] += (reward + discount*state[i][j+1])\n",
    "                elif j+1 > col-1:\n",
    "                    val[i][j] += (reward + discount*state[i][j])\n",
    "                if i-1 >= 0:\n",
    "                    val[i][j] += (reward + discount*state[i-1][j])\n",
    "                elif i-1 <0:\n",
    "                    val[i][j] += (reward + discount*state[i][j])\n",
    "                if i+1 <= row-1:\n",
    "                    val[i][j] += (reward + discount*state[i+1][j])\n",
    "                elif i+1 > row-1:\n",
    "                    val[i][j] += (reward + discount*state[i][j])\n",
    "\n",
    "                val[i][j] = val[i][j]/4\n",
    "                val[i][j] = round(val[i][j], 2)\n",
    "\n",
    "        if np.sum(np.abs(val-state)) < 1e-4:\n",
    "            break\n",
    "        state = np.copy(val)        \n",
    "    print(state)\n",
    "\n",
    "iterative_policy(4, 4, -1, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 2\n",
    "#Random Policy\n",
    "\n",
    "def iter_policy_evol(discount):\n",
    "    state = np.arange(25, dtype = float)\n",
    "    val = np.arange(25, dtype = float)\n",
    "    state = state.reshape((5,5))\n",
    "    val = val.reshape((5,5))\n",
    "    state = np.zeros_like(state)\n",
    "    val = np.zeros_like(val)\n",
    "\n",
    "    while True:\n",
    "        for i in range(5):\n",
    "            for j in range(5):\n",
    "                val[i][j] = 0\n",
    "                ##Action: UP\n",
    "                reward, prob, dest = move([i, j], Action.UP.value)\n",
    "                val[i][j] += prob*(reward + discount*(state[dest[0]][dest[1]]))\n",
    "                ##Action: DOWN\n",
    "                reward, prob, dest = move([i, j], Action.DOWN.value)\n",
    "                val[i][j] += prob*(reward + discount*(state[dest[0]][dest[1]]))\n",
    "                ##Action: LEFT\n",
    "                reward, prob, dest = move([i, j], Action.LEFT.value)\n",
    "                val[i][j] += prob*(reward + discount*(state[dest[0]][dest[1]]))\n",
    "                ##Action: RIGHT\n",
    "                reward, prob, dest = move([i, j], Action.RIGHT.value)\n",
    "                val[i][j] += prob*(reward + discount*(state[dest[0]][dest[1]]))\n",
    "\n",
    "                val[i][j] = round(val[i][j],2)\n",
    "        \n",
    "        if np.sum(np.abs(val-state)) < 1e-4:\n",
    "            break\n",
    "        state = np.copy(val)\n",
    "    \n",
    "    print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def move(currstate, dir):\n",
    "    if currstate == [0, 1]:\n",
    "        reward = 10\n",
    "        prob = 0.25\n",
    "        deststate = [4, 1]\n",
    "    elif currstate == [0,3]:\n",
    "        reward = 5\n",
    "        prob = 0.25\n",
    "        deststate = [2, 3]\n",
    "    elif currstate[0]+dir[0] < 0 or currstate[0]+dir[0] > 4 or currstate[1]+dir[1] < 0 or currstate[1]+dir[1] > 4:\n",
    "        reward = -1\n",
    "        prob = 0.25\n",
    "        deststate = currstate\n",
    "    else:\n",
    "        reward = 0\n",
    "        prob = 0.25\n",
    "        deststate = np.array(currstate) + np.array(dir)\n",
    "    return reward, prob, deststate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[[ 3.32  8.8   4.43  5.32  1.48]\n [ 1.53  3.    2.25  1.91  0.54]\n [ 0.06  0.74  0.68  0.36 -0.4 ]\n [-0.96 -0.43 -0.35 -0.58 -1.17]\n [-1.84 -1.33 -1.22 -1.41 -1.96]]\n"
    }
   ],
   "source": [
    "## Random Policy\n",
    "iter_policy_evol(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Value Iteration for optimal state vale funtion\n",
    "theta = 1e-4\n",
    "def value_iteration(discount):\n",
    "    \n",
    "    state = np.arange(25, dtype = float)\n",
    "    val = np.arange(25, dtype = float)\n",
    "    state = state.reshape((5,5))\n",
    "    val = val.reshape((5,5))\n",
    "    state = np.zeros_like(state)\n",
    "    val = np.zeros_like(val)\n",
    "\n",
    "    while True:\n",
    "        for i in range(5):\n",
    "            for j in range(5):\n",
    "                val[i][j] = 0\n",
    "                ##Action: UP\n",
    "                reward, prob, dest = move([i, j], Action.UP.value)\n",
    "                val[i][j] = max(val[i][j], reward + discount*(state[dest[0]][dest[1]]))\n",
    "                ##Action: DOWN\n",
    "                reward, prob, dest = move([i, j], Action.DOWN.value)\n",
    "                val[i][j] = max(val[i][j], reward + discount*(state[dest[0]][dest[1]]))\n",
    "                ##Action: LEFT\n",
    "                reward, prob, dest = move([i, j], Action.LEFT.value)\n",
    "                val[i][j] = max(val[i][j], reward + discount*(state[dest[0]][dest[1]]))\n",
    "                ##Action: RIGHT\n",
    "                reward, prob, dest = move([i, j], Action.RIGHT.value)\n",
    "                val[i][j] = max(val[i][j], reward + discount*(state[dest[0]][dest[1]]))\n",
    "                \n",
    "                val[i][j] = round(val[i][j],2)\n",
    "        \n",
    "        if np.sum(np.abs(val-state)) < theta:\n",
    "            break\n",
    "        state = np.copy(val)\n",
    "    \n",
    "    print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[[21.96 24.4  21.96 19.4  17.46]\n [19.76 21.96 19.76 17.78 16.  ]\n [17.78 19.76 17.78 16.   14.4 ]\n [16.   17.78 16.   14.4  12.96]\n [14.4  16.   14.4  12.96 11.66]]\n"
    }
   ],
   "source": [
    "value_iteration(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}